{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import seaborn.objects as so\n",
    "import utils as utils\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dat from csv\n",
    "df=utils.get_df('data.csv')\n",
    "sales=utils.get_df('sales.csv')\n",
    "df=pd.concat([df, sales['saleamt']],axis = 1)\n",
    "df=df.dropna(axis=0)\n",
    "\n",
    "# encoding categorical data\n",
    "enc = LabelEncoder()\n",
    "enc.fit(df['zipcode'])\n",
    "df['zipcode']=enc.transform(df['zipcode'])\n",
    "enc.fit(df['yearbuilt'])\n",
    "df['yearbuilt']=enc.transform(df['yearbuilt'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['yearbuilt','universalsize','beds','bathstotal','zipcode']],df['saleamt'], test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "clf = HistGradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predications = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting results\n",
    "fig, ax=plt.subplots()\n",
    "ax.scatter(x=y_test,y=predications,alpha=0.1)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()])-2000000,  # max of both axes\n",
    "]\n",
    "ax.axline((0, 0), slope=1)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "ax.ticklabel_format(useOffset=False,style=\"plain\")\n",
    "plt.xlabel(\"Actual Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "clf2=svm.LinearSVR(max_iter=1000000)\n",
    "inNames=['yearbuilt','universalsize','beds','bathstotal','zipcode']\n",
    "clf2.fit(X_train[inNames], y_train)\n",
    "\n",
    "predications2 = clf2.predict(X_test[inNames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting results\n",
    "fig, ax=plt.subplots()\n",
    "ax.scatter(x=y_test,y=predications2,alpha=0.1)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "ax.axline((0, 0), slope=1)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "ax.ticklabel_format(useOffset=False,style=\"plain\")\n",
    "plt.xlabel(\"Actual Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError as rms\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError as mae\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data=utils.get_df('data.csv')\n",
    "sales=utils.get_df('sales.csv')\n",
    "data=pd.concat([data, sales['saleamt']],axis = 1)\n",
    "data=data[['yearbuilt','universalsize','beds','bathstotal','zipcode','saleamt']]\n",
    "# encoding categorical data\n",
    "enc = LabelEncoder()\n",
    "print(data.head(3))\n",
    "enc.fit(data['zipcode'])\n",
    "data['zipcode']=enc.transform(data['zipcode'])\n",
    "enc.fit(data['yearbuilt'])\n",
    "data['yearbuilt']=enc.transform(data['yearbuilt'])\n",
    "print(data.head(3))\n",
    "data=data.dropna(axis=0)\n",
    "inNames=['yearbuilt','universalsize','beds','bathstotal','zipcode']\n",
    "outNames=['saleamt']\n",
    "normData, minVal, maxVal = utils.minNormalize(data)\n",
    "\n",
    "train, val, test = utils.splitData(normData, seed=142)\n",
    "\n",
    "# set hyperparams\n",
    "# variables to tune\n",
    "epochs = 1000\n",
    "batch = 200\n",
    "p = 10\n",
    "nlayers = 6\n",
    "mindelta = 1e-5\n",
    "LR = 1e-4\n",
    "\n",
    "# build the model\n",
    "model = utils.buildModel(nlayers,\n",
    "                   metrics=[rms(), mae()],\n",
    "                   optimizer=Adam(learning_rate=LR))\n",
    "\n",
    "# fit the model\n",
    "# stop the model if the validation loss levels off\n",
    "cb = EarlyStopping(monitor='val_loss',\n",
    "                   min_delta=mindelta,\n",
    "                   patience=p,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# reduce learning rate to try to improve results\n",
    "lrCalib = ReduceLROnPlateau(monitor='val_loss',\n",
    "                            factor=1e-2,\n",
    "                            patience=5,\n",
    "                            cooldown=5,\n",
    "                            verbose=1)\n",
    "\n",
    "# fit the model using the above two callbacks\n",
    "hist = model.fit(train[inNames], train[outNames],\n",
    "                 validation_data=(val[inNames], val[outNames]),\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batch,\n",
    "                 verbose=0,\n",
    "                 callbacks=[cb, lrCalib])\n",
    "\n",
    "# test with testing data\n",
    "# predict with model and testing values\n",
    "predNorm = model.predict(test[inNames])\n",
    "pred = utils.inverseMinNormalize(predNorm, minVal, maxVal)\n",
    "trueamt=utils.inverseMinNormalize(test[outNames], minVal, maxVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting results\n",
    "fig, ax=plt.subplots()\n",
    "ax.scatter(x=trueamt,y=pred,alpha=0.1)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "ax.axline((0, 0), slope=1)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "ax.ticklabel_format(useOffset=False,style=\"plain\")\n",
    "plt.xlabel(\"Actual Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
